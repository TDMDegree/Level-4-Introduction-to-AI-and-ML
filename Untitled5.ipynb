{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+fURdFwmczZ43vYL0CiNI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TDMDegree/Level-4-Introduction-to-AI-and-ML/blob/main/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jewti8ZkB5ee"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Introduction\n",
        "\n",
        "The adult dataset is from the 1994 Census database. Details of this dataset can be found at UCI Machine Learning Repository. My main aim is to create a simple GUI, so that users can input their own data and get a prediction of whether their income will exceed $50,000. The objectives that I will follow to complete my main aim are set out below :\n",
        "\n",
        "    Clean the data - Replace or delete missing data,\n",
        "    Explore the data - delete any unnecessary fields and reduce the variance of individual features\n",
        "    Normalise the data - convert the needed data for modelling\n",
        "    Explore the machine learning algorithms\n",
        "    Optimise the selected machine learning algorithm\n",
        "    Create the GUI\n",
        "\n"
      ],
      "metadata": {
        "id": "1tdoOXXvB7JQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stage 1 : Exploratory data analysis (EDA)"
      ],
      "metadata": {
        "id": "_h5BHf_PB_KM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1 - Present the code tells me all of the columns, datatypes and\n",
        " records"
      ],
      "metadata": {
        "id": "G9NtzH0MChSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 1 :\n",
        "# You will need to import the correct libraries , read the csv file Salary.txt and make sure that columns have the following names\n",
        "#names = [ \"age\" ,\"workclass\", \"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\n",
        "#\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"label\"]\n",
        "# You should complete task one."
      ],
      "metadata": {
        "id": "ERfjA111C1QZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2- Which 2 columns do not explain the type of information it is storing ? Can you delete this 2 columns"
      ],
      "metadata": {
        "id": "qSuxX1bRDgDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the code to drop the columns\n"
      ],
      "metadata": {
        "id": "JtwSMMGxHZVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 3 - From the information file on the dataset, we know that all missing data was represented as \"?\". Change this to NaN"
      ],
      "metadata": {
        "id": "Kv2mWPCyHlZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 3 - Add the code to change all \"?\"\" to NaN . In my answer, I used numpy.NaN"
      ],
      "metadata": {
        "id": "kf0gjTslH00W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 4 - Produce a report on the total number of null values for each column"
      ],
      "metadata": {
        "id": "U5KArw3DIDhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print all the columns with the total number of null values"
      ],
      "metadata": {
        "id": "SltqSKX-a6ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5 - Before we delete these records, more information is needed to find out how much data would be lost if we deleted all the missing data."
      ],
      "metadata": {
        "id": "EFD43V4XbAvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create two dataframes. Drop the Null values from one of them and then compare the record\n",
        "#differences to see how many records would be deleted"
      ],
      "metadata": {
        "id": "jKvSq4XKa6bR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploring the data"
      ],
      "metadata": {
        "id": "bYRyybF8bgEh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5 - using the native-country column, where we could potentially drop the null value records and ...\n",
        "\n",
        "Create a graph that shows the different values within that column and the value count for each value.\n",
        "\n",
        "**or **\n",
        "\n",
        "Show the percentage of each of the different values within that column"
      ],
      "metadata": {
        "id": "WQwGa6wccLtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete task 5"
      ],
      "metadata": {
        "id": "Ah4aE8hux7sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "From the information above, we can see that 1 variance of this feature has over 91% of the data. A decision was made to change all missing data from the Native Country column to equal \"United States\".\n",
        "\n",
        "Additional, the majority of the other variances had such a low number of records that a decision was made to try and combine the countries together in a way that could add to the model. The decision was to use the information from the website :\n",
        "\n",
        "https://www.nationsonline.org/oneworld/GNI_PPP_of_countries.htm\n",
        "\n",
        "to split the countries into high_PPP ,medium_PPP and low_PPP.\n",
        "\n",
        "Task 6 - Replace all of np.NaN with United-States and loop round each of the arrays to replace based on high_PPP ,medium_PPP and low_PPP\n",
        "\n",
        "low_PPP = [\" Honduras\", \" Vietnam\",\" Cambodia\",\" Laos\",\" Haiti\",\n",
        "               \" Yugoslavia\",\" India\",\" Guatemala\", \" Nicaragua\"]\n",
        "\n",
        "\n",
        "medium_PPP = [\" Trinadad&Tobago\",\" Poland\" ,\" Mexico\" , \" Thailand\",\" Iran\",\" Columbia\", \" Peru\", \" Philippines\" ,\" China\",\" Ecuador\" ,\n",
        "         \" Cuba\",\" El-Salvador\",\" Jamaica\",\" South\"]\n",
        "\n",
        "high_PPP = [\" Holand-Netherlands\",\" Scotland\",\" Ireland\",\" Hong\",\" Beligum\" ,\" Japan\",\" Italy\",\" England\",\" Germany\",\" Canada\",\" France\",\" Taiwan\",\" Greece\",\" Portugal\" , \" Hungary\",\" Outlying-US(Guam-USVI-etc)\", \" Puerto-Rico\", \" Dominican-Republic\"]\n"
      ],
      "metadata": {
        "id": "66Ah1pVXyQDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Complete task 6"
      ],
      "metadata": {
        "id": "KL-_Nc7bzxtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step was to look at the working class data and how the data is distributed.\n",
        "\n",
        "Task 7 - Create a graph that shows the value count from the WorkClass column"
      ],
      "metadata": {
        "id": "28G9O21tz3SD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Complete task 7"
      ],
      "metadata": {
        "id": "KjHru-PzzqK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The majority of the data is Privately employed. With the data being skewed to the Private sector,the missing data for the working class column was placed into the Private Column.\n",
        "\n",
        "In addition to editing the missing data, a decision was made to combine fields that had a high correlation. The people who never work and the people who are without work were placed in the same category.\n",
        "\n",
        "However the Government job categories remained as the mean salary for the different levels are significantly different.\n",
        "\n",
        "-Federal government - $70,000\n",
        "\n",
        "-State government - $53,180\n",
        "\n",
        "-Local goverment - $47,230\n",
        "(Information retrieved at https://work.chron.com/average-salary-government-employees-7863.html)\n",
        "\n",
        "For the self employed columns, although no additional data was found showing a difference between incorporated self employers and unincorporated self-employees. It was thought that a person would incorporate their company when it grows to a significant size and so there could be a significant difference between the 2 categories. This resulted in the 2 categories being left as they were.\n",
        "\n",
        "Task 8 - Replace the NaN to private within the workclass column and combine the never-worked and without-pay to \"Umemployed\"\n",
        "\n",
        "Display the new data in the same graph as task 7"
      ],
      "metadata": {
        "id": "0EZ3BWXD5PQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code for task 8"
      ],
      "metadata": {
        "id": "CbTcL1h151En"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An examination of the last column, Occupation, show now occur.\n",
        "\n",
        "Task 9 - Present a graph that shows the value count for the \"Occupation\" column."
      ],
      "metadata": {
        "id": "7mlc0ZEK535n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for Task 9"
      ],
      "metadata": {
        "id": "7EvUG6Cb6VDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The spread of the data was much more even. 3 options were considered for the missing data. The first option was to create a model that used the other features to predict which occupation the record belonged to. The second option was to delete the data. The last option was to convert the missing data to an intentional out-of-range value. This would allow some of the prediction models to ignore that piece of data.\n",
        "\n",
        "The results of that examination showed that 1843 would still be lost. After creating a model using KNNclasifer, the model came to only a 33% chance of guessing the correct label. Additionally, due to the size of the remaining sample,it was deemed acceptable to lose this number of records.\n",
        "\n",
        "Task 10 - Drop the remaining NaN values"
      ],
      "metadata": {
        "id": "JOjuubis6Yr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete Task 10"
      ],
      "metadata": {
        "id": "A6mQ1pm763za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Once all the missing data was either replaced or deleted. The other columns were examined to see if the varience in each columns could be reduced.\n",
        "\n",
        "To get a better idea if certain data categories could be combined an examine on the bias of dataframe was conducted.\n",
        "\n",
        "Task 11 - Show the number of records that are above and below 50,000"
      ],
      "metadata": {
        "id": "tvO12Ur96-TL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete task 11"
      ],
      "metadata": {
        "id": "JpaFi7aH7Ruy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using this information, a graph was created from the education column that showed the distribution of the data in each of the eductional categories.\n",
        "\n",
        "Task 12 - Create a graph that shows each of the education values and the number of individuals for over and under 50,000"
      ],
      "metadata": {
        "id": "SH4y1ULR7Xvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete task 12"
      ],
      "metadata": {
        "id": "PqKyzyqvDFNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A decision was made to combine all categories that were below the High School graduate. As the belief was that anyone who dropped out of highschool wouldn't be using their acdamic ability to aid them in their career.\n",
        "\n",
        "Task 13 - replace the following values\n",
        "\n",
        "[\" 11th\",\" 10th\",\" 7th-8th\",\" 9th\",\" 12th\",\" 5th-6th\",\" 1st-4th\",\" Preschool\"]\n",
        "\n",
        "to dropouts"
      ],
      "metadata": {
        "id": "E9k7rmsADJsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete Task 13"
      ],
      "metadata": {
        "id": "Pm09DvvT7JEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalising the data **\n",
        "\n",
        "The data has been cleaned and combined to make it more effective in the modeling process.However, currently there are still a number of columns that have an unsuitable datatype for some of the machine learning algorithms that I will be using.\n",
        "\n",
        "\n",
        "\n",
        "I will be converting all the object datatypes to a numerical type. The options that I have for this are using the Labelencoder and OneHotEncoder.\n",
        "\n",
        "Due to the non-ordinal relations between the data categories in each column. I have chosen to use pandas.get_dummies on the object datatypes -\n",
        "\n",
        " [\"workclass\",\"education\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"native-country\" were converted to a numeric value.]\n"
      ],
      "metadata": {
        "id": "7-Dk_LZPDxyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "features = df[[\"workclass\",\"education\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"native-country\"]]\n",
        "new_features = pd.get_dummies(features)"
      ],
      "metadata": {
        "id": "SyktpmQnJGrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These features are then added to the original dataframe, and the original columns deleted."
      ],
      "metadata": {
        "id": "7rj_caePJO1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.reset_index(inplace= True)\n",
        "new_features.reset_index(inplace= True)\n",
        "df = pd.merge(df,new_features,on=\"index\",how=\"inner\")\n",
        "df.head(2)\n",
        "df = df.drop([\"index\",\"workclass\",\"education\",\"marital-status\",\"relationship\",\"race\",\"sex\",\n",
        "               \"native-country\",\"occupation\"],1)\n",
        "df.head(2)"
      ],
      "metadata": {
        "id": "WmXH0JqzJTt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Continuing with the necessary conversion of the data, the label column was updated so that:\n",
        "\n",
        "0 = Below $50,000\n",
        "\n",
        "1 = Above $50,000\n"
      ],
      "metadata": {
        "id": "fxgQWcNKJaFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"label\"] = df[\"label\"].apply(lambda x : 0 if x ==\" <=50K\" else 1)\n",
        "label_df = df[\"label\"]\n",
        "features = df.drop(\"label\",1)\n",
        "features.head(2)\n",
        "print(features.columns)"
      ],
      "metadata": {
        "id": "bkg6nf26Jh49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The features then had to be normalised as the differences between some of the values were so great that it could affect the accuracy of the models.\n",
        "\n",
        "The MinMaxScaler was used to transforms the data.\n"
      ],
      "metadata": {
        "id": "39lzvj17JmOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(features)\n",
        "joblib.dump(scaler, 'MinMaxScaler.pkl')\n",
        "scaled_df = scaler.transform(features)"
      ],
      "metadata": {
        "id": "dQ1K2TbeJyPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exploring the machine learning algorithms**\n",
        "\n",
        "\n",
        "\n",
        "With the transformation of the data complete, a selection of algorithms were chosen to explore the best method to predict the salary classification. Below are the selected algorithms :\n",
        "\n",
        "1)KNeighborsClassifier\n",
        "\n",
        "2)Linear Regression\n",
        "\n",
        "4)Random Forest\n",
        "\n",
        "5)Extra Trees\n",
        "\n",
        "6)Support Vector Machine\n",
        "\n",
        "7)Neural Network\n",
        "\n"
      ],
      "metadata": {
        "id": "bLyRjXf6J0Kx"
      }
    }
  ]
}