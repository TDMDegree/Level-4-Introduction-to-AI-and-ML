{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TDMDegree/Level-4-Introduction-to-AI-and-ML/blob/main/Apriori%20-%20Association%20Rule%20Learning%20Challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTOQrUOBMcM4"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "# Apriori Algorithm - Association rule learning\n",
        "\n",
        "In this tutorial, we are going to use the association Rule Learning with Apriori to discover interesting relations between our variables. We are going to looking at links between different items within a shop.\n",
        "\n",
        "For more information about these topics, please check in the following links:\n",
        "\n",
        "Association rule learning - https://en.wikipedia.org/wiki/Association_rule_learning\n",
        "\n",
        "Apriori algorithm - https://en.wikipedia.org/wiki/Apriori_algorithm\n",
        "\n",
        "Data set - https://www.kaggle.com/datasets/heeraldedhia/groceries-dataset\n",
        "\n",
        "# Exploring the Data\n",
        "\n",
        "When selecting data for association rule mining using the Apriori algorithm, several important considerations must be taken into account to ensure meaningful and actionable results. Here are the key aspects to consider:\n",
        "\n",
        "1) Relevance of Data - You should be checking the frequency of the data items. Items that appear very infrequently may not provide useful rules.  **- You must show this in your report .**\n",
        "\n",
        "2) Categorical Data: The Apriori algorithm is typically used with categorical data (e.g., items in a shopping cart). Ensure that the data is categorical or has been appropriately binned if using numerical data.  **- You must show this in your report**\n",
        "\n",
        "3) Data Cleaning: Ensure that the data is clean, with no missing, duplicated, or incomplete or incorrect data can lead to misleading associations. **- You must show this in your report **\n",
        "\n",
        "4) Item Grouping - You will need to be able to group the items into different sets (e.g., products bought together in a single shopping cart or product bought by a single customer). **- You should think about this when selecting your data.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's Start our setup\n",
        "\n",
        "Google Colab provides a cloud-based Python environment with many pre-installed libraries. However, it doesn't include every possible library, especially specialized ones, which is often used for machine learning and data mining tasks such as the Apriori algorithm. This line :\n",
        "\n",
        "\"*!pip install apyori*\"\n",
        "\n",
        "ensures that the required library is installed before you attempt to use it in your code.\n",
        "\n"
      ],
      "metadata": {
        "id": "O3ULEIlPp7-f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiRw8PhaQ6iL",
        "outputId": "fe35df7a-34cb-4752-e253-8f4de7506f33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting apyori\n",
            "  Downloading apyori-1.1.2.tar.gz (8.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: apyori\n",
            "  Building wheel for apyori (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for apyori: filename=apyori-1.1.2-py3-none-any.whl size=5954 sha256=b9c770ff1980f520f4a89bd8af77c058ca98872649dc120397f1cd8841185c82\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/3d/a6/d317a6fb32be58a602b1e8c6b5d6f31f79322da554cad2a5ea\n",
            "Successfully built apyori\n",
            "Installing collected packages: apyori\n",
            "Successfully installed apyori-1.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install apyori\n",
        "from apyori import apriori\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring the Data - Code\n",
        "\n",
        "**1. Categorical Data**\n",
        "\n",
        "The dataset provided contains three columns: Member_number, Date, and itemDescription. Here, the itemDescription column represents the items purchased, which are categorical in nature. Categorical data refers to data that can be divided into specific categories or groups. In this case, each item in the itemDescription column is a category, like \"tropical fruit,\" \"whole milk,\" or \"pip fruit.\"\n",
        "\n",
        "**Why Categorical Data is Important for Apriori:**\n",
        "\n",
        "The Apriori algorithm is designed to work with categorical data, specifically item sets, to identify frequent itemsets and generate association rules.\n",
        "\n",
        "The items in itemDescription represent distinct categories of products, which can be analysed for patterns of co-occurrence (e.g., which items are frequently bought together).\n",
        "\n",
        "**2. Item Grouping**\n",
        "\n",
        "Both Member_number and Date columns can be used to group the  transactions.\n",
        "\n",
        "Group Items into Transactions:\n",
        "\n",
        "To perform association rule mining, we need to group the transaction. This can be done by grouping the dataset by Member_number or Date or both. After grouping, could give you different association rules.\n",
        "       \n"
      ],
      "metadata": {
        "id": "oYUJAnBhqjIc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HwgfvlyTMKlz"
      },
      "outputs": [],
      "source": [
        "# Task 1 - read the Groceries_dataset and find out if the data can be grouped and is suitable for association rule mining\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below shows that there are enough transactions to create meaningful association rules and that there are no incorrect item descriptions. I could potentially remove items with counts lower than 10, although I could also increase the confidence threshold in the analysis to eliminate any weak rules during the association rule mining process. However, it is important to be aware of low counts within your data exploration."
      ],
      "metadata": {
        "id": "_bYrX5wHuxWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2  - find out if values are enough to make good rules\n",
        "\n"
      ],
      "metadata": {
        "id": "5RWMX5fAudhF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below cleans the data by checking for any duplicates and identifying any missing values that might impact the rules generated."
      ],
      "metadata": {
        "id": "MJZ4vbKAw2gJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3 - Check for missing data and any duplicated records\n",
        "\n",
        "\n",
        "# Check for missing data\n"
      ],
      "metadata": {
        "id": "Kxov3cH5wsWO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOLtF_5CNewI"
      },
      "source": [
        "We will then create three groups and examine the rules associated with each grouping. The three groups are:\n",
        "\n",
        "1) Grouping by month of transaction.\n",
        "\n",
        "2) Grouping by member's transactions.\n",
        "\n",
        "3) Grouping by member's transactions per month."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zNJQpT2SN8wc"
      },
      "outputs": [],
      "source": [
        "# Task 4 - Grouping the data\n",
        "\n",
        "# I first need to change the data into a date data type\n",
        "\n",
        "\n",
        "# Extract Year-Month and create a new column\n",
        "\n",
        "\n",
        "# Create 3 groupings  -  1- Group items by Year and Month  , 2 - group the items by members , 3 - group the items by both members and date\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA1zXCQqOXGH"
      },
      "source": [
        "\n",
        "\n",
        "Apyori is a Python library that provides an implementation of the Apriori algorithm, which is a popular algorithm for association rule mining in data mining. Association rule mining is a technique to discover relationships between variables in large datasets.\n",
        "\n",
        "The apriori() function in apyori takes the following parameters:\n",
        "\n",
        "  **transactions : **A list of transactions. Each transaction is itself a list containing the items bought together.\n",
        "\n",
        "  **min_support :** Minimum support threshold. This parameter specifies the minimum frequency of an itemset to be considered significant. It is usually set as a small value between 0 and 1.\n",
        "\n",
        "  **min_confidence :** Minimum confidence threshold. This parameter specifies the minimum confidence level for the rules to be considered significant. It is usually set as a small value between 0 and 1.\n",
        "\n",
        "  **min_lift :** Minimum lift threshold. This parameter specifies the minimum lift value for the rules to be considered significant. Lift measures how much more likely the antecedent and consequent of a rule are to occur together compared to if they were statistically independent.\n",
        "\n",
        "Lets try to calculate the value for these parameters.These targets should be supported by literatue.\n",
        "\n",
        "So, our as per our target,\n",
        "\n",
        " ** min_support :** An item must appear in the list at least 3 times, divided by len(datset) i.e = 3 / 728 = 0.00412087912\n",
        "\n",
        "  **min_confidence :** We will start with 0.8 and them increase or decrease as per the rules observed.\n",
        "\n",
        "  min_lift : Similar to min_confidence.\n",
        "\n",
        "  min_length & max_length : Since we want just one product that goes along with a product, min and max length must be 2.\n",
        "\n",
        "\n",
        "Unlike all of the other models, we can't use the dataframe or series with his model and so we have to put it into an array. Below is the code to iterate around the dataframe and add it to an array.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "J3dWIz16Op43"
      },
      "outputs": [],
      "source": [
        "# Task 5 - Turn each grouped data from task 4 into a python list\n",
        "\n",
        "\n",
        "# Task 6 - Create 3 apriori model using the python list data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWXlNnRbMYsr"
      },
      "source": [
        "Unfortunately, the output isn't in a DataFrame either, so I am going to convert it back into one. The code is a bit more complex and uses list comprehensions to create arrays for each of the values. You should be able to use this code to extract the data and put it back into a DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "vrIeNrOzSji3",
        "outputId": "6a06e0b9-3f79-43ab-8e2f-be043143d493"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Month_group_rules' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5b856f3a83c5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Displaying the first results coming directly from the output of the apriori function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mMonth_group_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMonth_group_rules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mMember_group_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMember_group_rules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mMember_Month_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMember_Month_rules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Month_group_rules' is not defined"
          ]
        }
      ],
      "source": [
        "# Displaying the first results coming directly from the output of the apriori function\n",
        "Month_group_results = list(Month_group_rules)\n",
        "Member_group_results = list(Member_group_rules)\n",
        "Member_Month_results = list(Member_Month_rules)\n",
        "\n",
        "# Putting the results well organised into a Pandas DataFrame\n",
        "def inspect(results):\n",
        "    lhs         = [tuple(result[2][0][0])[0] for result in results]\n",
        "    rhs         = [tuple(result[2][0][1])[0] for result in results]\n",
        "    supports    = [result[1] for result in results]\n",
        "    confidences = [result[2][0][2] for result in results]\n",
        "    lifts       = [result[2][0][3] for result in results]\n",
        "    return list(zip(lhs, rhs, supports, confidences, lifts))\n",
        "\n",
        "Month_group_results_DataFrame = pd.DataFrame(inspect(Month_group_results), columns = ['Left Hand Side', 'Right Hand Side', 'Support', 'Confidence', 'Lift'])\n",
        "Member_group_results_DataFrame = pd.DataFrame(inspect(Member_group_results), columns = ['Left Hand Side', 'Right Hand Side', 'Support', 'Confidence', 'Lift'])\n",
        "Member_Month_results_DataFrame = pd.DataFrame(inspect(Member_Month_results), columns = ['Left Hand Side', 'Right Hand Side', 'Support', 'Confidence', 'Lift'])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 7 Sort the new dataframes by confidence and displaying the results\n",
        "\n"
      ],
      "metadata": {
        "id": "DgBnF6RoNGaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I am going to do an analysis on the \"Rules for transactions by members in a month\".\n",
        "\n",
        "Each row in the table represents an association rule, showing items that tend to be purchased together. Let's break down what each column represents and what the results tell us:\n",
        "Columns:\n",
        "\n",
        "Left Hand Side (LHS): The item(s) on the left-hand side of the rule, which can be considered as the \"antecedent\" or \"if\" part of the rule.\n",
        "\n",
        "Right Hand Side (RHS): The item(s) on the right-hand side of the rule, which can be considered as the \"consequent\" or \"then\" part of the rule.\n",
        "\n",
        "Support: The proportion of transactions in which both the LHS and RHS items appear together. A support of 0.000072 means that this combination of items appears in 0.0072% of the total transactions.\n",
        "   \n",
        "Confidence: The likelihood that a transaction containing the LHS will also contain the RHS. A confidence of 1.0 (or 100%) indicates that every time the LHS appears, the RHS also appears.\n",
        "  \n",
        "Lift: This metric measures how much more likely the RHS is to appear when the LHS is present, compared to its general occurrence in the dataset. A lift greater than 1 indicates a positive correlation between the items.\n",
        "\n",
        "**Analysis:**\n",
        "\n",
        "All the rules shown have a confidence of 1.0, meaning that whenever the LHS item is purchased, the RHS item is always purchased as well. This indicates a strong relationship between these items.\n",
        "        \n",
        "The lift values are significantly greater than 1, suggesting that the RHS items are much more likely to be purchased when the LHS items are in the basket compared to random chance. For example, a lift of 114.92 for \"kitchen utensil -> pasta\" means that pasta is about 115 times more likely to be bought when a kitchen utensil is purchased than it would be by random chance.\n",
        "\n",
        "The support values are very low (0.000072), meaning these item combinations are quite rare in the dataset. This suggests that while the associations are strong, they occur in only a tiny fraction of all transactions."
      ],
      "metadata": {
        "id": "vL8bEXY4XjcN"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXZA06oBUFM2dL4TqsnK4d",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}